{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time\n",
    "from datetime import datetime\n",
    "import json\n",
    "from zipfile import ZipFile\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import zipfile\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define PATH constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = \"data\"\n",
    "HTML_PATH = BASE_PATH + \"/html\"\n",
    "USER_PATH = BASE_PATH + \"/users\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Get Clubs IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40"
     ]
    }
   ],
   "source": [
    "def get_number(string):\n",
    "    return int(string.strip().replace(\",\", \"\"))\n",
    "\n",
    "\n",
    "clubs_id = set()\n",
    "possibles_users = 0\n",
    "page = 1\n",
    "\n",
    "while True:\n",
    "    print(f\"\\r{page}\", end=\"\")\n",
    "\n",
    "    time.sleep(3)  # Wait 3 seconds per page\n",
    "    data = requests.get(f\"https://myanimelist.net/clubs.php?p={page}\")\n",
    "    soup = BeautifulSoup(data.text, \"html.parser\")\n",
    "    rows = soup.find_all(\"tr\", {\"class\": \"table-data\"})\n",
    "    for row in rows:\n",
    "        members = get_number(row.find(\"td\", {\"class\": \"ac\"}).text)\n",
    "        club_id = get_number(\n",
    "            row.find(\"a\", {\"class\": \"fw-b\"}).get(\"href\").split(\"=\")[-1]\n",
    "        )\n",
    "        if (\n",
    "            club_id not in clubs_id and members > 30\n",
    "        ):  # Only save groups with more than 30 members\n",
    "            possibles_users += members\n",
    "            clubs_id.add(club_id)\n",
    "\n",
    "    page += 1\n",
    "    if possibles_users > 1000000:  # Threshold to stop\n",
    "        break\n",
    "\n",
    "with open(f\"{BASE_PATH}/clubs.txt\", \"w\") as file:\n",
    "    for club in clubs_id:\n",
    "        file.write(f\"{club}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Get usernames in every clubs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(f\"{BASE_PATH}/users_list.txt\"):\n",
    "    with open(f\"{BASE_PATH}/users_list.txt\", \"w\", encoding=\"UTF-8\") as file:\n",
    "        pass\n",
    "    \n",
    "if not os.path.exists(f\"{BASE_PATH}/_revised_clubs.txt\"):\n",
    "    with open(f\"{BASE_PATH}/_revised_clubs.txt\", \"w\", encoding=\"UTF-8\") as file:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0, 1087)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(f\"{BASE_PATH}/clubs.txt\") as file:\n",
    "    clubs_id = [x.strip() for x in file.readlines()]\n",
    "\n",
    "with open(f\"{BASE_PATH}/users_list.txt\", encoding=\"UTF-8\") as file:\n",
    "    users = set([x.strip() for x in file.readlines()])\n",
    "\n",
    "with open(f\"{BASE_PATH}/_revised_clubs.txt\", encoding=\"UTF-8\") as file:\n",
    "    revised_clubs = set([int(x.strip()) for x in file.readlines()])\n",
    "\n",
    "len(users), len(revised_clubs), len(clubs_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting jupyternotify\n",
      "  Downloading jupyternotify-0.1.15.tar.gz (7.2 kB)\n",
      "Requirement already satisfied: ipython in c:\\users\\11459\\anaconda3\\lib\\site-packages (from jupyternotify) (7.22.0)\n",
      "Requirement already satisfied: jupyter in c:\\users\\11459\\anaconda3\\lib\\site-packages (from jupyternotify) (1.0.0)\n",
      "Requirement already satisfied: pygments in c:\\users\\11459\\anaconda3\\lib\\site-packages (from ipython->jupyternotify) (2.8.1)\n",
      "Requirement already satisfied: backcall in c:\\users\\11459\\anaconda3\\lib\\site-packages (from ipython->jupyternotify) (0.2.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in c:\\users\\11459\\anaconda3\\lib\\site-packages (from ipython->jupyternotify) (3.0.17)\n",
      "Requirement already satisfied: traitlets>=4.2 in c:\\users\\11459\\anaconda3\\lib\\site-packages (from ipython->jupyternotify) (5.0.5)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\11459\\anaconda3\\lib\\site-packages (from ipython->jupyternotify) (0.7.5)\n",
      "Requirement already satisfied: decorator in c:\\users\\11459\\anaconda3\\lib\\site-packages (from ipython->jupyternotify) (5.0.6)\n",
      "Requirement already satisfied: colorama in c:\\users\\11459\\anaconda3\\lib\\site-packages (from ipython->jupyternotify) (0.4.4)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\11459\\anaconda3\\lib\\site-packages (from ipython->jupyternotify) (0.17.2)\n",
      "Requirement already satisfied: setuptools>=18.5 in c:\\users\\11459\\anaconda3\\lib\\site-packages (from ipython->jupyternotify) (52.0.0.post20210125)\n",
      "Requirement already satisfied: parso<0.8.0,>=0.7.0 in c:\\users\\11459\\anaconda3\\lib\\site-packages (from jedi>=0.16->ipython->jupyternotify) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\11459\\anaconda3\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->jupyternotify) (0.2.5)\n",
      "Requirement already satisfied: ipython-genutils in c:\\users\\11459\\anaconda3\\lib\\site-packages (from traitlets>=4.2->ipython->jupyternotify) (0.2.0)\n",
      "Requirement already satisfied: qtconsole in c:\\users\\11459\\anaconda3\\lib\\site-packages (from jupyter->jupyternotify) (5.0.3)\n",
      "Requirement already satisfied: ipykernel in c:\\users\\11459\\anaconda3\\lib\\site-packages (from jupyter->jupyternotify) (5.3.4)\n",
      "Requirement already satisfied: jupyter-console in c:\\users\\11459\\anaconda3\\lib\\site-packages (from jupyter->jupyternotify) (6.4.0)\n",
      "Requirement already satisfied: nbconvert in c:\\users\\11459\\anaconda3\\lib\\site-packages (from jupyter->jupyternotify) (6.0.7)\n",
      "Requirement already satisfied: ipywidgets in c:\\users\\11459\\anaconda3\\lib\\site-packages (from jupyter->jupyternotify) (7.6.3)\n",
      "Requirement already satisfied: notebook in c:\\users\\11459\\anaconda3\\lib\\site-packages (from jupyter->jupyternotify) (6.3.0)\n",
      "Requirement already satisfied: tornado>=4.2 in c:\\users\\11459\\anaconda3\\lib\\site-packages (from ipykernel->jupyter->jupyternotify) (6.1)\n",
      "Requirement already satisfied: jupyter-client in c:\\users\\11459\\anaconda3\\lib\\site-packages (from ipykernel->jupyter->jupyternotify) (6.1.12)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in c:\\users\\11459\\anaconda3\\lib\\site-packages (from ipywidgets->jupyter->jupyternotify) (3.5.1)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in c:\\users\\11459\\anaconda3\\lib\\site-packages (from ipywidgets->jupyter->jupyternotify) (1.0.0)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in c:\\users\\11459\\anaconda3\\lib\\site-packages (from ipywidgets->jupyter->jupyternotify) (5.1.3)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in c:\\users\\11459\\anaconda3\\lib\\site-packages (from nbformat>=4.2.0->ipywidgets->jupyter->jupyternotify) (3.2.0)\n",
      "Requirement already satisfied: jupyter-core in c:\\users\\11459\\anaconda3\\lib\\site-packages (from nbformat>=4.2.0->ipywidgets->jupyter->jupyternotify) (4.7.1)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in c:\\users\\11459\\anaconda3\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter->jupyternotify) (0.17.3)\n",
      "Requirement already satisfied: six>=1.11.0 in c:\\users\\11459\\anaconda3\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter->jupyternotify) (1.15.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\11459\\anaconda3\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter->jupyternotify) (20.3.0)\n",
      "Requirement already satisfied: terminado>=0.8.3 in c:\\users\\11459\\anaconda3\\lib\\site-packages (from notebook->jupyter->jupyternotify) (0.9.4)\n",
      "Requirement already satisfied: Send2Trash>=1.5.0 in c:\\users\\11459\\anaconda3\\lib\\site-packages (from notebook->jupyter->jupyternotify) (1.5.0)\n",
      "Requirement already satisfied: prometheus-client in c:\\users\\11459\\anaconda3\\lib\\site-packages (from notebook->jupyter->jupyternotify) (0.10.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\11459\\anaconda3\\lib\\site-packages (from notebook->jupyter->jupyternotify) (2.11.3)\n",
      "Requirement already satisfied: argon2-cffi in c:\\users\\11459\\anaconda3\\lib\\site-packages (from notebook->jupyter->jupyternotify) (20.1.0)\n",
      "Requirement already satisfied: pyzmq>=17 in c:\\users\\11459\\anaconda3\\lib\\site-packages (from notebook->jupyter->jupyternotify) (20.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\11459\\anaconda3\\lib\\site-packages (from jupyter-client->ipykernel->jupyter->jupyternotify) (2.8.1)\n",
      "Requirement already satisfied: pywin32>=1.0 in c:\\users\\11459\\anaconda3\\lib\\site-packages (from jupyter-core->nbformat>=4.2.0->ipywidgets->jupyter->jupyternotify) (227)\n",
      "Requirement already satisfied: pywinpty>=0.5 in c:\\users\\11459\\anaconda3\\lib\\site-packages (from terminado>=0.8.3->notebook->jupyter->jupyternotify) (0.5.7)\n",
      "Requirement already satisfied: cffi>=1.0.0 in c:\\users\\11459\\anaconda3\\lib\\site-packages (from argon2-cffi->notebook->jupyter->jupyternotify) (1.14.5)\n",
      "Requirement already satisfied: pycparser in c:\\users\\11459\\anaconda3\\lib\\site-packages (from cffi>=1.0.0->argon2-cffi->notebook->jupyter->jupyternotify) (2.20)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\11459\\anaconda3\\lib\\site-packages (from jinja2->notebook->jupyter->jupyternotify) (1.1.1)\n",
      "Requirement already satisfied: defusedxml in c:\\users\\11459\\anaconda3\\lib\\site-packages (from nbconvert->jupyter->jupyternotify) (0.7.1)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\users\\11459\\anaconda3\\lib\\site-packages (from nbconvert->jupyter->jupyternotify) (1.4.3)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in c:\\users\\11459\\anaconda3\\lib\\site-packages (from nbconvert->jupyter->jupyternotify) (0.3)\n",
      "Requirement already satisfied: bleach in c:\\users\\11459\\anaconda3\\lib\\site-packages (from nbconvert->jupyter->jupyternotify) (3.3.0)\n",
      "Requirement already satisfied: testpath in c:\\users\\11459\\anaconda3\\lib\\site-packages (from nbconvert->jupyter->jupyternotify) (0.4.4)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in c:\\users\\11459\\anaconda3\\lib\\site-packages (from nbconvert->jupyter->jupyternotify) (0.8.4)\n",
      "Requirement already satisfied: jupyterlab-pygments in c:\\users\\11459\\anaconda3\\lib\\site-packages (from nbconvert->jupyter->jupyternotify) (0.1.2)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in c:\\users\\11459\\anaconda3\\lib\\site-packages (from nbconvert->jupyter->jupyternotify) (0.5.3)\n",
      "Requirement already satisfied: async-generator in c:\\users\\11459\\anaconda3\\lib\\site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->jupyter->jupyternotify) (1.10)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\11459\\anaconda3\\lib\\site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->jupyter->jupyternotify) (1.5.1)\n",
      "Requirement already satisfied: webencodings in c:\\users\\11459\\anaconda3\\lib\\site-packages (from bleach->nbconvert->jupyter->jupyternotify) (0.5.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\11459\\anaconda3\\lib\\site-packages (from bleach->nbconvert->jupyter->jupyternotify) (20.9)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\11459\\anaconda3\\lib\\site-packages (from packaging->bleach->nbconvert->jupyter->jupyternotify) (2.4.7)\n",
      "Requirement already satisfied: qtpy in c:\\users\\11459\\anaconda3\\lib\\site-packages (from qtconsole->jupyter->jupyternotify) (1.9.0)\n",
      "Building wheels for collected packages: jupyternotify\n",
      "  Building wheel for jupyternotify (setup.py): started\n",
      "  Building wheel for jupyternotify (setup.py): finished with status 'done'\n",
      "  Created wheel for jupyternotify: filename=jupyternotify-0.1.15-py3-none-any.whl size=8721 sha256=19a3b65b9c3daec931773d9341e820e4c30a3c544709421927859cdf8bfbcaa3\n",
      "  Stored in directory: c:\\users\\11459\\appdata\\local\\pip\\cache\\wheels\\2d\\ff\\e5\\bced088d6443a70f72ee86f9e46f11056c981100c2d3cfadfb\n",
      "Successfully built jupyternotify\n",
      "Installing collected packages: jupyternotify\n",
      "Successfully installed jupyternotify-0.1.15\n"
     ]
    }
   ],
   "source": [
    "!pip install jupyternotify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "if (!(\"Notification\" in window)) {\n",
       "    alert(\"This browser does not support desktop notifications, so the %%notify magic will not work.\");\n",
       "} else if (Notification.permission !== 'granted' && Notification.permission !== 'denied') {\n",
       "    Notification.requestPermission(function (permission) {\n",
       "        if(!('permission' in Notification)) {\n",
       "            Notification.permission = permission;\n",
       "        }\n",
       "    })\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext jupyternotify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/1087 --> 01"
     ]
    }
   ],
   "source": [
    "%%notify -m \"get username finish\"\n",
    "\n",
    "for i, club_id in enumerate(clubs_id):\n",
    "    if club_id in revised_clubs:\n",
    "        continue\n",
    "\n",
    "    page = 1\n",
    "    while True:\n",
    "        print(f\"\\r{i+1}/{len(clubs_id)} --> {str(page).zfill(2)}\", end=\"\")\n",
    "        link = f\"https://api.jikan.moe/v3/club/{club_id}/members/{page}\"\n",
    "\n",
    "        try:\n",
    "            time.sleep(4.2)\n",
    "            data = requests.get(link)\n",
    "        except KeyboardInterrupt:\n",
    "            raise KeyboardInterrupt()\n",
    "        except:  # Other exception wait 2 min and try again\n",
    "            time.sleep(120)\n",
    "            continue\n",
    "\n",
    "        if data.status_code != 200:\n",
    "            break\n",
    "\n",
    "        with open(f\"{BASE_PATH}/users_list.txt\", \"a\", encoding=\"UTF-8\") as file:\n",
    "            for user in map(lambda x: x[\"username\"], json.loads(data.text)[\"members\"]):\n",
    "                if user not in users and user != \"\":\n",
    "                    file.write(f\"{user}\\n\")\n",
    "                    users.add(user)\n",
    "        page += 1\n",
    "\n",
    "    revised_clubs.add(club_id)\n",
    "    with open(f\"{BASE_PATH}/_revised_clubs.txt\", \"a\", encoding=\"UTF-8\") as file:\n",
    "        file.write(f\"{club_id}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{BASE_PATH}/users_list.txt\", encoding=\"UTF-8\") as file:\n",
    "    users = list(set([x.strip() for x in file.readlines()]))[1:]\n",
    "    random.shuffle(users)\n",
    "\n",
    "with open(f\"{BASE_PATH}/users.csv\", \"w\", encoding=\"UTF-8\") as file:\n",
    "    file.write(\"user_id,username\\n\")\n",
    "    for i, user in enumerate(users):\n",
    "        file.write(f\"{i},{user}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Get animelist per user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{BASE_PATH}/users.csv\", \"r\", encoding=\"UTF-8\") as file:\n",
    "    file.readline()\n",
    "    users = [x.strip().split(\",\") for x in file.readlines()]\n",
    "    users = [(int(x[0]), x[1]) for x in users]\n",
    "\n",
    "last_revised_users = -1\n",
    "if os.path.exists(f\"{BASE_PATH}/_last_revised_users.txt\"):\n",
    "    with open(f\"{BASE_PATH}/_last_revised_users.txt\", \"r\", encoding=\"UTF-8\") as file:\n",
    "        last_revised_users = int(file.readline())\n",
    "\n",
    "len(users), last_revised_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext jupyternotify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%notify -m \"animelist finish\"\n",
    "for i, (user_id, username) in enumerate(users):\n",
    "    if user_id <= last_revised_users:\n",
    "        continue\n",
    "\n",
    "    now = datetime.now()\n",
    "    print(f'\\r{str(now).split(\".\")[0]} --> {i+1}/{len(users)}', end=\"\")\n",
    "    page = 1\n",
    "    all_animes = []\n",
    "\n",
    "    while True:\n",
    "        link = f\"https://api.jikan.moe/v3/user/{username}/animelist/all?page={page}\"\n",
    "        try:\n",
    "            time.sleep(4.2)\n",
    "            data = requests.get(link, timeout=15)\n",
    "        except KeyboardInterrupt:\n",
    "            raise KeyboardInterrupt()\n",
    "        except:  # Other exception wait 2 min and try again\n",
    "            time.sleep(120)\n",
    "            continue\n",
    "\n",
    "        if data.status_code != 200:\n",
    "            break\n",
    "\n",
    "        data = json.loads(data.text)\n",
    "        for anime in data[\"anime\"]:\n",
    "            all_animes.append((anime[\"mal_id\"], anime[\"score\"], anime[\"watching_status\"], anime[\"watched_episodes\"]))\n",
    "\n",
    "        page += 1\n",
    "        if len(data[\"anime\"]) < 300:\n",
    "            break\n",
    "\n",
    "    if len(all_animes) != 0:\n",
    "        with open(f\"{USER_PATH}/{user_id}.csv\", \"w\") as f1:\n",
    "            f1.write(f\"anime_id,score,watching_status,watched_episodes\\n\")\n",
    "            for anime_id, anime_score, watching_status, watched_episodes in all_animes:\n",
    "                f1.write(\n",
    "                    f\"{anime_id},{anime_score},{watching_status},{watched_episodes}\\n\"\n",
    "                )\n",
    "\n",
    "    revised_users = user_id\n",
    "    with open(f\"{BASE_PATH}/_last_revised_users.txt\", \"w\", encoding=\"UTF-8\") as file:\n",
    "        file.write(f\"{user_id}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Download Anime HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_anime = set()\n",
    "folder = os.listdir(USER_PATH)\n",
    "for i, user_file in enumerate(folder):\n",
    "    if \".csv\" not in user_file:\n",
    "        continue\n",
    "\n",
    "    print(f\"\\r{i + 1}/{len(folder)}\", end=\"\")\n",
    "    with open(f\"{USER_PATH}/{user_file}\", \"r\") as file:\n",
    "        file.readline()\n",
    "        for line in file:\n",
    "            anime = line.strip().split(\",\")[0]\n",
    "            unique_anime.add(anime)\n",
    "\n",
    "print(\"         \")\n",
    "print(len(unique_anime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX = 7  # MAX SECOND TO WAIT PER REQUEST\n",
    "MIN = 4  # MIN SECONDS TO WAIT PER REQUEST\n",
    "\n",
    "\n",
    "def sleep():\n",
    "    time_to_sleep = random.random() * (MAX - MIN) + MIN\n",
    "    time.sleep(time_to_sleep)\n",
    "\n",
    "\n",
    "def get_link_by_text(soup, anime_id, text):\n",
    "    links = list(filter(lambda x: anime_id in x[\"href\"], soup.find_all(\"a\", text=text)))\n",
    "    return links[0][\"href\"]\n",
    "\n",
    "\n",
    "def save(path, data):\n",
    "    with open(path, \"w\", encoding=\"UTF-8\") as file:\n",
    "        file.write(data)\n",
    "\n",
    "\n",
    "def save_link(link, anime_id, name):\n",
    "    sleep()\n",
    "    path = f\"{HTML_PATH}/{anime_id}/{name}.html\"\n",
    "    data = requests.get(link)\n",
    "    soup = BeautifulSoup(data.text, \"html.parser\")\n",
    "    soup.script.decompose()\n",
    "    save(path, soup.prettify())\n",
    "    return soup\n",
    "\n",
    "\n",
    "def save_reviews(link, anime_id):\n",
    "    page = 1\n",
    "    while True:\n",
    "        sleep()\n",
    "        actual_link = f\"{link}?p={page}\"\n",
    "        data = requests.get(actual_link)\n",
    "        soup = BeautifulSoup(data.text, \"html.parser\")\n",
    "        reviews = soup.find_all(\"a\", text=\"Overall Rating\")\n",
    "        if len(reviews) == 0:\n",
    "            break\n",
    "\n",
    "        path = f\"{HTML_PATH}/{anime_id}/reviews_{page}.html\"\n",
    "        soup.script.decompose()\n",
    "        save(path, soup.prettify())\n",
    "        page += 1\n",
    "\n",
    "\n",
    "def scrap_anime(anime_id):\n",
    "    path = f\"{HTML_PATH}/{anime_id}\"\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    sleep()\n",
    "    data = requests.get(f\"https://myanimelist.net/anime/{anime_id}\")\n",
    "\n",
    "    anime_info = data.text\n",
    "    soup = BeautifulSoup(anime_info, \"html.parser\")\n",
    "    soup.script.decompose()\n",
    "    save(f\"{HTML_PATH}/{anime_id}/details.html\", soup.prettify())\n",
    "\n",
    "    link_review = get_link_by_text(soup, anime_id, \"Reviews\")\n",
    "    link_recomendations = get_link_by_text(soup, anime_id, \"Recommendations\")\n",
    "    link_stats = get_link_by_text(soup, anime_id, \"Stats\")\n",
    "    link_staff = get_link_by_text(soup, anime_id, \"Characters & Staff\")\n",
    "    link_pictures = get_link_by_text(soup, anime_id, \"Pictures\")\n",
    "\n",
    "    save_link(link_pictures, anime_id, \"pictures\")\n",
    "    save_link(link_staff, anime_id, \"staff\")\n",
    "    save_link(link_stats, anime_id, \"stats\")\n",
    "    save_link(link_recomendations, anime_id, \"recomendations\")\n",
    "    save_reviews(link_review, anime_id)\n",
    "\n",
    "\n",
    "def zipdir(path, ziph):\n",
    "    # ziph is zipfile handle\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for file in files:\n",
    "            ziph.write(\n",
    "                os.path.join(root, file),\n",
    "                os.path.relpath(os.path.join(root, file), path),\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext jupyternotify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%notify -m \"Anime scrapping finish\"\n",
    "\n",
    "for i, anime_id in enumerate(unique_anime):\n",
    "    if os.path.isfile(f\"{HTML_PATH}/{anime_id}.zip\"):\n",
    "        continue\n",
    "\n",
    "    print(f\"\\r{i+1}/{len(unique_anime)}\", end=\"\")\n",
    "\n",
    "    try:\n",
    "        scrap_anime(anime_id)\n",
    "    except KeyboardInterrupt:\n",
    "        break\n",
    "    except:  # Other exception wait 2 min and try again\n",
    "        time.sleep(120)\n",
    "        continue\n",
    "\n",
    "    path = f\"{HTML_PATH}/{anime_id}\"\n",
    "    zipf = zipfile.ZipFile(f\"{path}.zip\", \"w\", zipfile.ZIP_DEFLATED)\n",
    "    zipdir(path, zipf)\n",
    "    zipf.close()\n",
    "\n",
    "    shutil.rmtree(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Scrapping Anime info from HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_zip(input_zip):\n",
    "    input_zip = ZipFile(input_zip)\n",
    "    return {name: input_zip.read(name) for name in input_zip.namelist()}\n",
    "\n",
    "KEYS = ['MAL_ID', 'Name', 'Score', 'Genders', 'English name', 'Japanese name', 'Type', 'Episodes',\n",
    "        'Aired', 'Premiered', 'Producers', 'Licensors', 'Studios', 'Source', 'Duration', 'Rating',\n",
    "        'Ranked', 'Popularity', 'Members', 'Favorites', 'Watching', 'Completed', 'On-Hold', 'Dropped',\n",
    "        'Plan to Watch', 'Score-10', 'Score-9', 'Score-8', 'Score-7', 'Score-6', 'Score-5', 'Score-4',\n",
    "        'Score-3', 'Score-2', 'Score-1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_name(info):\n",
    "    return info.find(\"h1\", {\"class\": \"title-name h1_bold_none\"}).text.strip()\n",
    "\n",
    "\n",
    "def get_english_name(info):\n",
    "    span = info.findAll(\"span\", {\"class\": \"dark_text\"})\n",
    "    return span.parent.text.strip()\n",
    "\n",
    "\n",
    "def get_table(a_soup):\n",
    "    return a_soup.find(\"div\", {\"class\": \"po-r js-statistics-info di-ib\"})\n",
    "\n",
    "\n",
    "def get_score(stats):\n",
    "    score = stats.find(\"span\", {\"itemprop\": \"ratingValue\"})\n",
    "    if score is None:\n",
    "        return \"Unknown\"\n",
    "    return score.text.strip()\n",
    "\n",
    "\n",
    "def get_gender(sum_info):\n",
    "    text = \", \".join(\n",
    "        [x.text.strip() for x in sum_info.findAll(\"span\", {\"itemprop\": \"genre\"})]\n",
    "    )\n",
    "    return text\n",
    "\n",
    "\n",
    "def get_description(sum_info):\n",
    "    return sum_info.find(\"td\", {\"class\": \"borderClass\", \"width\": \"225\"})\n",
    "\n",
    "\n",
    "def get_all_stats(soup):\n",
    "    return soup.find(\"div\", {\"id\": \"horiznav_nav\"}).parent.findAll(\n",
    "        \"div\", {\"class\": \"spaceit_pad\"}\n",
    "    )\n",
    "\n",
    "\n",
    "def get_info_anime(anime_id):\n",
    "    data = extract_zip(f\"data/html/{anime_id}.zip\")\n",
    "    anime_info = data[\"stats.html\"].decode()\n",
    "    soup = BeautifulSoup(anime_info, \"html.parser\")\n",
    "\n",
    "    stats = get_table(soup)\n",
    "    description = get_description(soup)\n",
    "    anime_info = {key: \"Unknown\" for key in KEYS}\n",
    "\n",
    "    anime_info[\"MAL_ID\"] = anime_id\n",
    "    anime_info[\"Name\"] = get_name(soup)\n",
    "    anime_info[\"Score\"] = get_score(stats)\n",
    "    anime_info[\"Genders\"] = get_gender(description)\n",
    "\n",
    "    for d in description.findAll(\"span\", {\"class\": \"dark_text\"}):\n",
    "        information = [x.strip().replace(\" \", \" \") for x in d.parent.text.split(\":\")]\n",
    "        category, value = information[0], \":\".join(information[1:])\n",
    "        value.replace(\"\\t\", \"\")\n",
    "\n",
    "        if category in [\"Broadcast\", \"Synonyms\", \"Genres\", \"Score\", \"Status\"]:\n",
    "            continue\n",
    "\n",
    "        if category in [\"Ranked\"]:\n",
    "            value = value.split(\"\\n\")[0]\n",
    "        if category in [\"Producers\", \"Licensors\", \"Studios\"]:\n",
    "            value = \", \".join([x.strip() for x in value.split(\",\")])\n",
    "        if category in [\"Ranked\", \"Popularity\"]:\n",
    "            value = value.replace(\"#\", \"\")\n",
    "        if category in [\"Members\", \"Favorites\"]:\n",
    "            value = value.replace(\",\", \"\")\n",
    "        if category in [\"English\", \"Japanese\"]:\n",
    "            category += \" name\"\n",
    "\n",
    "        anime_info[category] = value\n",
    "\n",
    "    # Stats (Watching, Completed, On-Hold, Dropped, Plan to Watch)\n",
    "    for d in get_all_stats(soup)[:5]:\n",
    "        category, value = [x.strip().replace(\" \", \" \") for x in d.text.split(\":\")]\n",
    "        value = value.replace(\",\", \"\")\n",
    "        anime_info[category] = value\n",
    "\n",
    "    # Stast votes per score\n",
    "    for d in get_all_stats(soup)[6:]:\n",
    "        score = d.parent.parent.find(\"td\", {\"class\": \"score-label\"}).text.strip()\n",
    "        value = [x.strip().replace(\" \", \" \") for x in d.text.split(\"%\")][1].strip(\n",
    "            \"(votes)\"\n",
    "        )\n",
    "        label = f\"Score-{score}\"\n",
    "        anime_info[label] = value.strip()\n",
    "\n",
    "    for key, value in anime_info.items():\n",
    "        if str(value) in [\"?\", \"None found, add some\", \"None\", \"N/A\", \"Not available\"]:\n",
    "            anime_info[key] = \"Unknown\"\n",
    "    return anime_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_info_anime(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate anime.tsv\n",
    "anime_revised = set()\n",
    "exist_file = os.path.exists(f\"{BASE_PATH}/anime.tsv\")\n",
    "\n",
    "if exist_file:\n",
    "    # If the file exist, include new data.\n",
    "    actual_data = pd.read_csv(f\"{BASE_PATH}/anime.tsv\", sep=\"\\t\")\n",
    "    anime_revised = list(actual_data.MAL_ID.unique())\n",
    "\n",
    "actual_data.head()\n",
    "total_data = []\n",
    "zips = os.listdir(HTML_PATH)\n",
    "for i, anime in enumerate(zips):\n",
    "    if not \".zip\" in anime:\n",
    "        continue\n",
    "\n",
    "    anime_id = int(anime.strip(\".zip\"))\n",
    "\n",
    "    if int(anime_id) in anime_revised:\n",
    "        continue\n",
    "\n",
    "    print(f\"\\r{i+1}/{len(zips)} ({anime_id})\", end=\"\")\n",
    "\n",
    "    anime_id = anime.strip(\".zip\")\n",
    "    total_data.append(get_info_anime(anime_id))\n",
    "\n",
    "if len(total_data):\n",
    "    df = pd.DataFrame.from_dict(total_data)\n",
    "    df[\"MAL_ID\"] = pd.to_numeric(df[\"MAL_ID\"])\n",
    "    df = df.sort_values(by=\"MAL_ID\").reset_index(drop=True)\n",
    "\n",
    "    if exist_file:\n",
    "        df = (\n",
    "            pd.concat([actual_data, df]).sort_values(by=\"MAL_ID\").reset_index(drop=True)\n",
    "        )\n",
    "\n",
    "else:\n",
    "    df = actual_data\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(f\"{BASE_PATH}/anime.tsv\", index=False, sep=\"\\t\", encoding=\"UTF-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Create rating_complete.csv\n",
    "\n",
    "This file only contain animes with `watching_status==2`(complete) and have been rated (`score!=0`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(f\"{BASE_PATH}/rating_complete.csv\"):\n",
    "    with open(f\"{BASE_PATH}/rating_complete.csv\", \"w\", encoding=\"UTF-8\") as file:\n",
    "        file.write(\"user_id,anime_id,rating\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_anime = set()\n",
    "all_users = sorted(os.listdir(USER_PATH), key=lambda x:int(x.split(\".\")[0]))\n",
    "\n",
    "with open(f\"{BASE_PATH}/rating_complete.csv\", \"a\") as f1:\n",
    "\n",
    "    for i, user_file in enumerate(all_users):\n",
    "        if not user_file.endswith(\".csv\"):\n",
    "            continue\n",
    "\n",
    "        print(f\"\\r{i+1}/{len(all_users)}\", end=\"\")\n",
    "\n",
    "        user_id = user_file.split(\".\")[0]\n",
    "        with open(f\"{USER_PATH}/{user_file}\", \"r\") as file:\n",
    "            file.readline()\n",
    "            for line in file:\n",
    "                anime_id, score, watching_status, _ = line.strip().split(\",\")\n",
    "                if int(watching_status) == 2 and int(score) != 0:\n",
    "                    f1.write(f\"{user_id},{anime_id},{score}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Unified animelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(f\"{BASE_PATH}/animelist.csv\"):\n",
    "    with open(f\"{BASE_PATH}/animelist.csv\", \"w\", encoding=\"UTF-8\") as file:\n",
    "        file.write(\"user_id,anime_id,rating,watching_status,watched_episodes\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_anime = set()\n",
    "all_users = sorted(os.listdir(USER_PATH), key=lambda x:int(x.split(\".\")[0]))\n",
    "\n",
    "with open(f\"{BASE_PATH}/animelist.csv\", \"a\") as f1:\n",
    "\n",
    "    for i, user_file in enumerate(all_users):\n",
    "        if not user_file.endswith(\".csv\"):\n",
    "            continue\n",
    "\n",
    "        print(f\"\\r{i+1}/{len(all_users)}\", end=\"\")\n",
    "\n",
    "        user_id = user_file.split(\".\")[0]\n",
    "        with open(f\"{USER_PATH}/{user_file}\", \"r\") as file:\n",
    "            file.readline()\n",
    "            for line in file:\n",
    "                anime_id, score, watching_status, watched_episodes = line.strip().split(\",\")\n",
    "                f1.write(f\"{user_id},{anime_id},{score},{watching_status},{watched_episodes}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
